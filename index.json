[{"authors":null,"categories":null,"content":"I am a computational linguist with a background in NLP and in psycholinguistics. I am interested in\n data-centered AI: how we can improve data quality to train better machine learning models on language tasks human-centered AI, that is how we can take humans (users, designers, crowdworkers and annotators) into account in all things AI to make the best of their intuitions and to interact with them in a fair way  ","date":1636588800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636588800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a computational linguist with a background in NLP and in psycholinguistics. I am interested in\n data-centered AI: how we can improve data quality to train better machine learning models on language tasks human-centered AI, that is how we can take humans (users, designers, crowdworkers and annotators) into account in all things AI to make the best of their intuitions and to interact with them in a fair way  ","tags":null,"title":"Alessandra Zarcone","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"http://azarcone.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Lianna Hrycyk","Alessandra Zarcone","Luzian Hahn"],"categories":null,"content":"","date":1636588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636588800,"objectID":"00ea854d1453538d3a661dde8de9c6a5","permalink":"http://azarcone.github.io/publication/2021-nlp4convai/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021-nlp4convai/","section":"publication","summary":"Incremental intent classification requires the assignment of intent labels to partial utterances. However, partial utterances do not necessarily contain enough information to be mapped to the intent class of their complete utterance (correctly and with a certain degree of confidence). Using the final interpretation as the ground truth to measure a classifier’s accuracy during intent classification of partial utterances is thus problematic. We release inCLINC, a dataset of partial and full utterances with human annotations of plausible intent labels for different portions of each utterance, as an upper (human) baseline for incremental intent classification. We analyse the incremental annotations and propose entropy reduction as a measure of human annotators’ convergence on an interpretation (i.e. intent label). We argue that, when the annotators do not converge to one or a few possible interpretations and yet the classifier already identifies the final intent class early on, it is a sign of overfitting that can be ascribed to artefacts in the dataset.","tags":["crowdsourcing","data-centric","human upper bound","incremental intent classification","incremental processing","Information Density","NLU"],"title":"Not So Fast, Classifier – Accuracy and Entropy Reduction in Incremental Intent Classification","type":"publication"},{"authors":["Alessandra Zarcone","Vera Demberg"],"categories":null,"content":"","date":1627257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627257600,"objectID":"7aade27170b204d4c6e4fd862ec84caa","permalink":"http://azarcone.github.io/publication/2021-cogsci/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021-cogsci/","section":"publication","summary":"The Uniform Information Density hypothesis (UID) predicts that lexical choice between long and short word forms depends on the predictability of the referent in context, and recent studies have shown such an effect of predictability on lexical choice during online production. We here set out to test whether the UID predictions hold up in a related setting, but different language (German) and different phenomenon, namely the choice between compounds (e.g. Badewanne / bathtub) or their base forms (Wanne / tub). Our study is consistent with the UID: we find that participants choose the shorter base form more often in predictive contexts, showing an active tendency to be information-theoretically efficient.","tags":["crowdsourcing","German compounds","expectation-based processing","incremental processing","Information Density","predictability","Rational Speech Act framework","referring expressions","script knowledge","Uniform Information Density hypothesis"],"title":"A bathtub by any other name: the reduction of German compounds in predictive contexts","type":"publication"},{"authors":["Alessandra Zarcone","Vera Demberg"],"categories":null,"content":"","date":1627257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627257600,"objectID":"0c497bd37c85ef6cf6491197e555640e","permalink":"http://azarcone.github.io/publication/2021-discproc/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021-discproc/","section":"publication","summary":"There is now a well-established literature showing that people anticipate upcoming concepts and words during language processing. Commonsense knowledge about typical event sequences and verbal selectional preferences can contribute to anticipating what will be mentioned next. We here investigate how temporal discourse connectives (before, after), which signal event ordering along a temporal dimension, modulate predictions for upcoming discourse referents. Our study analyses anticipatory gaze in the visual world and supports the idea that script knowledge, temporal connectives (before eating → menu, appetizer), and the verb’s selectional preferences (order → appetizer) jointly contribute to shaping rapid prediction of event participants.","tags":["discourse","expectation-based processing","incremental processing","script knowledge","world knowledge","visual world paradigm"],"title":"Interaction of Script Knowledge and Temporal Discourse Cues in a Visual World Study","type":"publication"},{"authors":["Alessandra Zarcone","Yannick Frommherz"],"categories":null,"content":"","date":1624233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624233600,"objectID":"98ad4b6581ce18c8866a24e529317e25","permalink":"http://azarcone.github.io/publication/2021-frontcomputsci/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021-frontcomputsci/","section":"publication","summary":"Despite their increasing success, user interactions with smart speech assistants (SAs) are still very limited compared to human-human dialogue. One way to make SA interactions more natural is to train the underlying natural language processing modules on data which reflects how humans would talk to a SA if it was capable of understanding and producing natural dialogue given a specific task. Such data can be collected applying a Wizard-of-Oz approach (WOz), where user and system side are played by humans. WOz allows researchers to simulate human-machine interaction while benefitting from the fact that all participants are human and thus dialogue-competent. More recent approaches have leveraged simple templates specifying a dialogue scenario for crowdsourcing large-scale datasets. Template-based collection efforts, however, come at the cost of data diversity and naturalness. We present a method to crowdsource dialogue data for the SA domain in the WOz framework, which aims at limiting researcher-induced bias in the data while still allowing for a low-resource, scalable data collection. Our method can also be applied to languages other than English (in our case German), for which fewer crowd-workers may be available. We collected data asynchronously, relying only on existing functionalities of Amazon Mechanical Turk, by formulating the task as a dialogue continuation task. Coherence in dialogues is ensured, as crowd-workers always read the dialogue history, and as a unifying scenario is provided for each dialogue. In order to limit bias in the data, rather than using template-based scenarios, we handcrafted situated scenarios which aimed at not pre-script-ing the task into every single detail and not priming the participants’ lexical choices. Our scenarios cued people’s knowledge of common situations and entities relevant for our task, without directly mentioning them, but relying on vague language and circumlocutions. We compare our data (which we publish as the CROWDSS corpus; n = 113 dialogues) with data from MultiWOZ, showing that our scenario approach led to considerably less scripting and priming and thus more ecologically-valid dialogue data. This suggests that small investments in the collection setup can go a long way in improving data quality, even in a low-resource setup.","tags":["crowdsourcing","data-centric","dialogue","ecological data","Human-Machine Interaction","Wizard-of-Oz"],"title":"Crowdsourcing ecologically-valid dialogue data for German","type":"publication"},{"authors":["Touhidul Alam","Alessandra Zarcone","Sebastian Padó"],"categories":null,"content":"","date":1623801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623801600,"objectID":"6b5cbedde421154443fcb6456970bf79","permalink":"http://azarcone.github.io/publication/2021-iwcs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021-iwcs/","section":"publication","summary":"Reliable tagging of Temporal Expressions (TEs, e.g., Book a table at L’Osteria for Sunday evening) is a central requirement for Voice Assistants (VAs). However, there is a dearth of resources and systems for the VA domain, since publicly-available temporal taggers are trained only on substantially different domains, such as news and clinical text. Since the cost of annotating large datasets is prohibitive, we investigate the trade-off between in-domain data and performance in DA-Time, a hybrid temporal tagger for the English VA domain which combines a neural architecture for robust TE recognition, with a parser-based TE normalizer. We find that transfer learning goes a long way even with as little as 25 in-domain sentences: DA-Time performs at the state of the art on the news domain, and substantially outperforms it on the VA domain.","tags":["domain adaptation","NLU","temporal expressions","temporal tagging","transfer learning","voice assistants"],"title":"New Domain, Major Effort? How Much Data is Necessary to Adapt a Temporal Tagger to the Voice Assistant Domain","type":"publication"},{"authors":["Alessandra Zarcone","吳恩達"],"categories":["Demo","教程"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"http://azarcone.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Alessandra Zarcone","Touhidul Alam","Zahra Kolagar"],"categories":null,"content":"","date":1589155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589155200,"objectID":"79ca6ebd7012e0bf844fe76c195a804c","permalink":"http://azarcone.github.io/publication/2020-lrec/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2020-lrec/","section":"publication","summary":"The recognition and automatic annotation of temporal expressions (e.g. “Add an event for tomorrow evening at eight to my calendar”) is a key module for AI voice assistants, in order to allow them to interact with apps (for example, a calendar app). However, in the NLP literature, research on temporal expressions has focused mostly on data from the news, from the clinical domain, and from social media. The voice assistant domain is very different than the typical domains that have been the focus of work on temporal expression identification, thus requiring a dedicated data collection. We present a crowdsourcing method for eliciting natural-language commands containing temporal expressions for an AI voice assistant, by using pictures and scenario descriptions. We annotated the elicited commands (480) as well as the commands in the Snips dataset following the TimeML/TIMEX3 annotation guidelines, reaching a total of 1188 annotated commands. The commands can be later used to train the NLU components of an AI voice assistant.","tags":["NLU","temporal expressions","temporal tagging","voice assistants"],"title":"PÂTÉ: A Corpus of Temporal Expressions for the In-car Voice Assistant Domain","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"http://azarcone.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"http://azarcone.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Alessandra Zarcone"],"categories":null,"content":"","date":1409529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409529600,"objectID":"e57de740aa79df6dc59d69a6d796207e","permalink":"http://azarcone.github.io/publication/2014-phdthesis/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2014-phdthesis/","section":"publication","summary":"During language understanding, people do not only rely on what they read or hear, but they also exploit implicit information. For example, when they process the expression 'begin the book', they understand it involves an event which is not explicitly mentioned (e.g. 'begin reading the book'). This thesis looks at these constructions, known as logical metonymies, which combine an event-selecting verb and entity-denoting object and involve covert events. Logical metonymies are an interesting challenge for theories of lexical semantics: they need to be reconciled with compositionality, they require the integration of context (writers typically write books, students typically read them), and they lie at the interface between lexicon and world knowledge (is the information that books are read stored in our mental lexicon or in our world knowledge?).\nI critically analyze previous hypotheses on logical metonymy with regard to the answer they provide to two core problems: the source problem (what events are retrieved? what type of event knowledge is assumed?) and the trigger problem (why do some constructions trigger a metonymic interpretation and others do not?). Lexicalist approaches claim that the metonymy arises from a type clash between the event-selecting verb and an entity-denoting object, and posit complex lexical items, encoding event information about artifacts (e.g. book → read), to explain the recovery of covert events. Pragmatic-based approaches argue against the idea that lexical items have an internal structure, suggesting that covert events arise from the underspecification of a logical metonymy and are inferred via non-lexical knowledge. I look with particular attention at the role of event knowledge, which lexicalist approaches place in our mental lexicon, while pragmatic-based approaches place it in our world knowledge.\nI propose a third hypothesis, based on thematic fit and generalized event knowledge of typical events and their participants, which have been shown to guide efficient incremental processing: I argue that contextual elements cue generalized event knowledge, which plays a key role in determining the covert event for a logical metonymy. I explore this hypothesis from an interdisciplinary perspective, employing both psycholinguistic experiments and computational models, in order to seek converging evidence and confront it with the theoretical investigation. The results from the psycholinguistic experiments and from the computational (distributional) models support the hypothesis that covert event retrieval is guided by generalized event knowledge. I also employ the computational models to analyze previous experimental results and to explore the hypothesis that thematic fit, informed by generalized event knowledge, is ultimately responsible for the trigger of the logical metonymy. I then report on more psycholinguistic evidence showing that a notion of type is indeed necessary to account for differences between metonymic and non-metonymic constructions, and that both type and thematic fit play a role in logical metonymy interpretation. Lastly, I argue for a context-sensitive model of logical metonymy interpretation that exploits an information-rich lexicon, but needs to rethink the notion of type and reconcile it with the notion of thematic fit.","tags":["logical metonymy","complement coercion","lexical meaning in context","world knowledge","expectation-based processing","distributional semantics"],"title":"Event Knowledge and Models of Logical Metonymy Interpretation","type":"publication"},{"authors":["Alessandra Zarcone"],"categories":null,"content":"","date":1237248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1237248000,"objectID":"9aaf432bd3fbc85554711dd354104e99","permalink":"http://azarcone.github.io/publication/2009-mathesis/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2009-mathesis/","section":"publication","summary":"Event types (ET) have been widely addressed in linguistics literature, but have received little attention in psycholinguitics, neurolinguistics and computational linguistics research. This thesis dissertation explores the nature of event types from a cognitive point of view: many descriptions and diagnostics on event types are available, but few studies have dealt with the problem of how event types are represented and processed in the mental lexicon. An important prerequisite for this sort of research is the building of a corpus of stimuli that meets our needs (web-based pre-tests were run to test the reliability of the stimuli, which should be balanced to control the variables known to affect processing costs) and an analysis of pre-existing literature in experimental psycholinguistics of event types. Our main concern was to explore new experimental settings in verb semantics psycholinguistics and to adapt them to this specific type of investigation: the choice of the method was narrowed down to the semantic priming paradigm, although the set of stimuli could also be suitable for other experimental settings, such as reading-time studies. The semantic priming paradigm was exploited to contrast processing effects on achievement verbs and activity verbs, which differ with respect to two superordinate features: durativity and resultativity. A series of priming experiments were run to explore differences and interactions between such features and the tense morphology and to evaluate the different contribution of the experimental setting in the observation and measurement of the effect: experiment 1 and experiment 2 followed a similar design and contrasted the effects of different neutral primes; experiment 3 focused on the interaction between event types and Italian tense morphology","tags":["lexical aspect","lexical meaning in context","semantic priming"],"title":"Empirical correlates of event types - a priming study","type":"publication"},{"authors":["Alessandra Zarcone"],"categories":null,"content":"","date":1160611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1160611200,"objectID":"f8f3d73e73d07a48cff9bb9f992dc9c0","permalink":"http://azarcone.github.io/publication/2006-bscthesis/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2006-bscthesis/","section":"publication","summary":"La presente relazione illustra i primi risultati di un'analisi computazionale dell'azionalità del verbo italiano, seguendo l'ipotesi (presentata per l'inglese americano da Siegel e McKeown (2000)) che specifici indicatori contestuali presenti in una frase possano fornire delle informazioni rilevanti sulla categoria azionale del verbo della frase stessa. Un modello computazionale della classificazione azionale può rivelarsi particolarmente interessante per il trattamento di fenomeni come le opposizioni infralessicali e la commutazione azionale. Il modello di classificazione azionale adottato è quello introdotto da Zeno Vendler, con particolare attenzione anche all'elaborazione teorica alle problematiche specifiche del verbo italiano presentate da Pier Marco Bertinetto. Il modello sperimentale adottato è l'apprendimento automatico supervisionato detto Maximum Entropy (principio della massimizzazione dell'entropia - Berger et al. 1996). L'uso dell'apprendimento automatico può essere un modo innovativo di modellizzare il problema della classificazione azionale, ma può anche fornire consistenza sperimentale alle correlazioni teoriche tra marche contestuali e categorie azionali: la rilevanza delle diverse marche contestuali è valutata in base ai risultati ottenuti dall'agente in grado di apprendere, che, dopo una prima fase di addestramento, deve decidere circa la categoria azionale di una determinata forma verbale. Un analizzatore di questo tipo sfrutta soltanto elementi presenti nel contesto, senza l'ausilio di informazioni semantiche interne al verbo stesso, nè conoscenze afferenti al dominio della pragmatica, che spesso nell'uomo hanno un ruolo rilevante.","tags":["human upper bound","lexical aspect","lexical meaning in context","Maximum Enthropy"],"title":"La classificazione azionale del verbo italiano: primi esperimenti computazionali","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"http://azarcone.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]