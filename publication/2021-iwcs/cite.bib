@inproceedings{alam-etal-2021-new,
    title = "New Domain, Major Effort? How Much Data is Necessary to Adapt a Temporal Tagger to the Voice Assistant Domain",
    author = "Alam, Touhidul  and
      Zarcone, Alessandra  and
      Pad{\'o}, Sebastian",
    booktitle = "Proceedings of the 14th International Conference on Computational Semantics (IWCS)",
    month = jun,
    year = "2021",
    address = "Groningen, The Netherlands (online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.iwcs-1.14",
    pages = "144--154",
    abstract = "Reliable tagging of Temporal Expressions (TEs, e.g., Book a table at L{'}Osteria for Sunday evening) is a central requirement for Voice Assistants (VAs). However, there is a dearth of resources and systems for the VA domain, since publicly-available temporal taggers are trained only on substantially different domains, such as news and clinical text. Since the cost of annotating large datasets is prohibitive, we investigate the trade-off between in-domain data and performance in DA-Time, a hybrid temporal tagger for the English VA domain which combines a neural architecture for robust TE recognition, with a parser-based TE normalizer. We find that transfer learning goes a long way even with as little as 25 in-domain sentences: DA-Time performs at the state of the art on the news domain, and substantially outperforms it on the VA domain.",
}
